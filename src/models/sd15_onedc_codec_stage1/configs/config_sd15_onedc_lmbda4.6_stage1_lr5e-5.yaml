# model params
model_id: runwayml/stable-diffusion-v1-5
vae_model_id: madebyollin/taesd
revision: ~
sdxl: false
num_denoising_step: 1
num_train_timesteps: 1000
denoising_timestep: 1000
conditioning_timestep: 999
tune_unet: false
use_large_vae: true         # for fast init compression module, may use tiny, but performance will drop.
vae_attn_patch: 16
num_visuals: 2
freeze_codec: false
freeze_codec_encoder: false
use_codeformer: true

# lora params
lora_config:
  lora_rank: 64
  lora_alpha: 8.0
  lora_dropout: 0.0

# codec params
codec:
  internal_ch: 512
  bottleneck_ch: 128
  unet_ch_config: [512, 768, 768]
  z_fsq_levels: [4,4,4,4,4,4,4]   # FSQ, equal to 16384 codebook

# pix loss params
codeformer_loss_weight: 0.001
codeformer_mse_weight: 0.01
pix_loss:
  pix_weight: 1.0
  lpips_weight: 1.0
  pix_loss_type: l1
  lmbda: 4.6              # for different bitrate, lmbda: [1.8, 2.9, 4.6, 7.4]
  lmbda_schedule:         # to stabilize training
    start_step: 0
    end_step: 4000
    start_value: 0.0001
    end_value: 4.6        # for different bitrate, lmbda: [1.8, 2.9, 4.6, 7.4]

# training params
local_rank: -1      # will be overwrited, ignore its value
seed: 33550336
train_iters: 400_000            # 400k for lr=5e-5, then you may manually adjust lr and continue training
gradient_checkpointing: false
use_fp16: true
warmup_step: 500
max_grad_norm: 5.0
gradient_accumulation_steps: 1
generator_lr: 5e-5              # 400k for lr=5e-5, then you may manually adjust lr and continue training
monitor_key_lower: total_loss   # monitor key for best model saving

# dataset params
resolution: 512
batch_size: 8
num_workers: 8
use_random_transform: true
random_resize_list: [512]
random_resize_prob: [0.2]
random_resize_batch_reduction: [1.0]
random_crop_list: [512, 1024]
random_crop_prob: [0.5, 0.3]
random_crop_batch_reduction: [1.0, 0.25]
train_dataset:
  dataset_1:
    target: data.common_canvas_set.CommonCanvas_HF_crop
    params:
      data_dir: ../dataset         # To your cc dataset path, which contain .arrow and .json files.
      crop_size: 1024
      loading_length: 10000         # how many .arrow files to load
eval_dataset: 
  dataset_1:
    target: data.trainset.COCO
    params:
      json_file: ~    # To your coco val json file path.
      root_dir: ~     # To your coco val images path.                    
      crop_size: 512
      random_crop: false

# log related
save_interval: 10_000
log_interval: 200
visual_interval: 2500
use_wandb: false                   # set to true to enable wandb logging, if not, use tensorboard.
wandb_entity: ~                    # replace with your wandb entity
wandb_project: ~                   # replace with your wandb project

# path params
max_checkpoint: 3
no_save: false                      # only for debug, enable by args --no_save, not set in config file.
checkpoint_path: ~                  # may not use?
unet_ckpt: ../logs/pretrain_dmd2/pytorch_model.bin    # set to pretrained DMD2 SD 1.5 checkpoint.
codec_ckpt: ~                       # place the model_1.safetensor previous training to here, if continue training.
unet_ckpt_lora: ~                   # place the model.safetensor previous training to here, if continue training.
codeformer_ckpt: ~                  # place the model_2.safetensor previous training to here, if continue training.
vqgan_ckpt: ../logs/pretrain_tokenizer/maskgit-vqgan-imagenet-f16-256.bin    # set to pretrained MaskGIT-VQGAN checkpoint path

# for continue training, just ignore it.
override_lr: ~
override_step: ~

# project name and save path
name: test_run                       # replace with your name
output_path: ../logs/experiments     # replace with your path
debug: false
disable_tqdm: false